{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix, recall_score, accuracy_score, precision_score, f1_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loaded in cleaned dataframe from Exploratory Data Analysis in Jupyter Notebook folder in this repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/clean_df.csv', index_col=0) # loaded up data and had two index colums so set to only have 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3333 entries, 0 to 3332\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   state                   3333 non-null   object \n",
      " 1   account length          3333 non-null   int64  \n",
      " 2   area code               3333 non-null   int64  \n",
      " 3   international plan      3333 non-null   int64  \n",
      " 4   voice mail plan         3333 non-null   int64  \n",
      " 5   number vmail messages   3333 non-null   int64  \n",
      " 6   total day calls         3333 non-null   int64  \n",
      " 7   total day charge        3333 non-null   float64\n",
      " 8   total eve calls         3333 non-null   int64  \n",
      " 9   total eve charge        3333 non-null   float64\n",
      " 10  total night calls       3333 non-null   int64  \n",
      " 11  total night charge      3333 non-null   float64\n",
      " 12  total intl calls        3333 non-null   int64  \n",
      " 13  total intl charge       3333 non-null   float64\n",
      " 14  customer service calls  3333 non-null   int64  \n",
      " 15  churn                   3333 non-null   int64  \n",
      "dtypes: float64(4), int64(11), object(1)\n",
      "memory usage: 442.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='churn')\n",
    "y = df.churn\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.8527410964385754\n",
      "Test : 0.8621103117505995\n"
     ]
    }
   ],
   "source": [
    "dr = DummyClassifier()\n",
    "\n",
    "dummy_model = dr.fit(X_train, y_train)\n",
    "dummy_train =dr.score(X_train,y_train)\n",
    "dummy_test = dr.score(X_test,y_test)\n",
    "\n",
    "print(f'Train: {dummy_train}')\n",
    "print(f'Test : {dummy_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = df[['state','area code']]\n",
    "\n",
    "num_cols = df.drop(columns=['state','area code', 'churn', 'international plan', 'voice mail plan'])\n",
    "\n",
    "#binary_cols = df[['international plan', 'voice mail plan']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "subpipe_num = Pipeline(steps=[('ss', StandardScaler())])\n",
    "subpipe_cat = Pipeline(steps=[('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['account length', 'number vmail messages', 'total day calls',\n",
       "       'total day charge', 'total eve calls', 'total eve charge',\n",
       "       'total night calls', 'total night charge', 'total intl calls',\n",
       "       'total intl charge', 'customer service calls'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(transformers= [\n",
    "    ('subpipe_num', subpipe_num, num_cols.columns),\n",
    "    ('subpipe_cat', subpipe_cat, [0,2])\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.527291</td>\n",
       "      <td>-0.582315</td>\n",
       "      <td>1.682410</td>\n",
       "      <td>-0.416881</td>\n",
       "      <td>1.120060</td>\n",
       "      <td>-0.302652</td>\n",
       "      <td>-2.121425</td>\n",
       "      <td>-0.085379</td>\n",
       "      <td>0.204352</td>\n",
       "      <td>-0.606383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.376394</td>\n",
       "      <td>-0.582315</td>\n",
       "      <td>-1.691942</td>\n",
       "      <td>-1.055485</td>\n",
       "      <td>-1.906901</td>\n",
       "      <td>-0.649130</td>\n",
       "      <td>-0.108357</td>\n",
       "      <td>-0.129149</td>\n",
       "      <td>0.613876</td>\n",
       "      <td>-0.181249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.023776</td>\n",
       "      <td>1.547862</td>\n",
       "      <td>1.329865</td>\n",
       "      <td>0.615205</td>\n",
       "      <td>-0.897914</td>\n",
       "      <td>-0.479333</td>\n",
       "      <td>-0.005122</td>\n",
       "      <td>0.111587</td>\n",
       "      <td>-0.614695</td>\n",
       "      <td>-0.473528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151564</td>\n",
       "      <td>-0.582315</td>\n",
       "      <td>0.070779</td>\n",
       "      <td>1.132324</td>\n",
       "      <td>0.867814</td>\n",
       "      <td>-1.433868</td>\n",
       "      <td>-0.418060</td>\n",
       "      <td>-0.312984</td>\n",
       "      <td>0.613876</td>\n",
       "      <td>0.536165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.429037</td>\n",
       "      <td>-0.582315</td>\n",
       "      <td>1.279502</td>\n",
       "      <td>0.403413</td>\n",
       "      <td>-0.696116</td>\n",
       "      <td>-0.720261</td>\n",
       "      <td>-0.830997</td>\n",
       "      <td>-0.120395</td>\n",
       "      <td>0.613876</td>\n",
       "      <td>0.071175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>-0.349406</td>\n",
       "      <td>-0.582315</td>\n",
       "      <td>0.423323</td>\n",
       "      <td>0.790445</td>\n",
       "      <td>-0.696116</td>\n",
       "      <td>-1.422395</td>\n",
       "      <td>-0.882614</td>\n",
       "      <td>1.731084</td>\n",
       "      <td>-0.205172</td>\n",
       "      <td>1.545859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>-0.574842</td>\n",
       "      <td>-0.582315</td>\n",
       "      <td>-0.785400</td>\n",
       "      <td>0.241074</td>\n",
       "      <td>0.262421</td>\n",
       "      <td>-0.552759</td>\n",
       "      <td>0.975603</td>\n",
       "      <td>-1.415993</td>\n",
       "      <td>-1.433743</td>\n",
       "      <td>-0.008538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>-1.025715</td>\n",
       "      <td>-0.582315</td>\n",
       "      <td>0.876594</td>\n",
       "      <td>0.255050</td>\n",
       "      <td>0.514668</td>\n",
       "      <td>-2.250729</td>\n",
       "      <td>1.749860</td>\n",
       "      <td>0.168488</td>\n",
       "      <td>1.432923</td>\n",
       "      <td>1.067583</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>-0.073873</td>\n",
       "      <td>-0.582315</td>\n",
       "      <td>0.322596</td>\n",
       "      <td>-1.957485</td>\n",
       "      <td>0.161523</td>\n",
       "      <td>-0.275118</td>\n",
       "      <td>0.511049</td>\n",
       "      <td>-0.514327</td>\n",
       "      <td>-0.205172</td>\n",
       "      <td>0.111031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>1.454086</td>\n",
       "      <td>-0.582315</td>\n",
       "      <td>0.121142</td>\n",
       "      <td>1.752651</td>\n",
       "      <td>0.413769</td>\n",
       "      <td>-0.213165</td>\n",
       "      <td>-0.366442</td>\n",
       "      <td>0.444240</td>\n",
       "      <td>0.204352</td>\n",
       "      <td>-1.004946</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2499 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.527291 -0.582315  1.682410 -0.416881  1.120060 -0.302652 -2.121425   \n",
       "1    -1.376394 -0.582315 -1.691942 -1.055485 -1.906901 -0.649130 -0.108357   \n",
       "2    -0.023776  1.547862  1.329865  0.615205 -0.897914 -0.479333 -0.005122   \n",
       "3     0.151564 -0.582315  0.070779  1.132324  0.867814 -1.433868 -0.418060   \n",
       "4     1.429037 -0.582315  1.279502  0.403413 -0.696116 -0.720261 -0.830997   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2494 -0.349406 -0.582315  0.423323  0.790445 -0.696116 -1.422395 -0.882614   \n",
       "2495 -0.574842 -0.582315 -0.785400  0.241074  0.262421 -0.552759  0.975603   \n",
       "2496 -1.025715 -0.582315  0.876594  0.255050  0.514668 -2.250729  1.749860   \n",
       "2497 -0.073873 -0.582315  0.322596 -1.957485  0.161523 -0.275118  0.511049   \n",
       "2498  1.454086 -0.582315  0.121142  1.752651  0.413769 -0.213165 -0.366442   \n",
       "\n",
       "            7         8         9   ...   57   58   59   60   61   62   63  \\\n",
       "0    -0.085379  0.204352 -0.606383  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1    -0.129149  0.613876 -0.181249  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "2     0.111587 -0.614695 -0.473528  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "3    -0.312984  0.613876  0.536165  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "4    -0.120395  0.613876  0.071175  ...  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "...        ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "2494  1.731084 -0.205172  1.545859  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2495 -1.415993 -1.433743 -0.008538  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "2496  0.168488  1.432923  1.067583  ...  1.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "2497 -0.514327 -0.205172  0.111031  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "2498  0.444240  0.204352 -1.004946  ...  1.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "\n",
       "       64   65   66  \n",
       "0     1.0  0.0  0.0  \n",
       "1     0.0  0.0  0.0  \n",
       "2     0.0  0.0  1.0  \n",
       "3     0.0  0.0  0.0  \n",
       "4     0.0  0.0  0.0  \n",
       "...   ...  ...  ...  \n",
       "2494  1.0  0.0  0.0  \n",
       "2495  0.0  0.0  0.0  \n",
       "2496  0.0  0.0  0.0  \n",
       "2497  0.0  0.0  0.0  \n",
       "2498  0.0  0.0  0.0  \n",
       "\n",
       "[2499 rows x 67 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(ct.fit_transform(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_no_scaler = ct = ColumnTransformer(transformers= [\n",
    "    ('subpipe_cat', subpipe_cat, [0,2])\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>26.71</td>\n",
       "      <td>122.0</td>\n",
       "      <td>15.72</td>\n",
       "      <td>59.0</td>\n",
       "      <td>8.87</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.30</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>20.77</td>\n",
       "      <td>62.0</td>\n",
       "      <td>14.21</td>\n",
       "      <td>98.0</td>\n",
       "      <td>8.77</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.62</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>36.31</td>\n",
       "      <td>82.0</td>\n",
       "      <td>14.95</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9.32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>41.12</td>\n",
       "      <td>117.0</td>\n",
       "      <td>10.79</td>\n",
       "      <td>92.0</td>\n",
       "      <td>8.35</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>34.34</td>\n",
       "      <td>86.0</td>\n",
       "      <td>13.90</td>\n",
       "      <td>84.0</td>\n",
       "      <td>8.79</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.81</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>37.94</td>\n",
       "      <td>86.0</td>\n",
       "      <td>10.84</td>\n",
       "      <td>83.0</td>\n",
       "      <td>13.02</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>32.83</td>\n",
       "      <td>105.0</td>\n",
       "      <td>14.63</td>\n",
       "      <td>119.0</td>\n",
       "      <td>5.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>32.96</td>\n",
       "      <td>110.0</td>\n",
       "      <td>7.23</td>\n",
       "      <td>134.0</td>\n",
       "      <td>9.45</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.56</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>12.38</td>\n",
       "      <td>103.0</td>\n",
       "      <td>15.84</td>\n",
       "      <td>110.0</td>\n",
       "      <td>7.89</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.84</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>46.89</td>\n",
       "      <td>108.0</td>\n",
       "      <td>16.11</td>\n",
       "      <td>93.0</td>\n",
       "      <td>10.08</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2499 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9   ...    57     58  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...   0.0  134.0   \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   67.0   \n",
       "2     1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  29.0  127.0   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  102.0   \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  126.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...    ...   \n",
       "2494  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  109.0   \n",
       "2495  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   85.0   \n",
       "2496  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  118.0   \n",
       "2497  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  107.0   \n",
       "2498  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  103.0   \n",
       "\n",
       "         59     60     61     62     63   64    65   66  \n",
       "0     26.71  122.0  15.72   59.0   8.87  5.0  2.30  4.0  \n",
       "1     20.77   62.0  14.21   98.0   8.77  6.0  2.62  1.0  \n",
       "2     36.31   82.0  14.95  100.0   9.32  3.0  2.40  1.0  \n",
       "3     41.12  117.0  10.79   92.0   8.35  6.0  3.16  0.0  \n",
       "4     34.34   86.0  13.90   84.0   8.79  6.0  2.81  1.0  \n",
       "...     ...    ...    ...    ...    ...  ...   ...  ...  \n",
       "2494  37.94   86.0  10.84   83.0  13.02  4.0  3.92  3.0  \n",
       "2495  32.83  105.0  14.63  119.0   5.83  1.0  2.75  0.0  \n",
       "2496  32.96  110.0   7.23  134.0   9.45  8.0  3.56  3.0  \n",
       "2497  12.38  103.0  15.84  110.0   7.89  4.0  2.84  3.0  \n",
       "2498  46.89  108.0  16.11   93.0  10.08  5.0  2.00  2.0  \n",
       "\n",
       "[2499 rows x 67 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(ct_no_scaler.fit_transform(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "imb_pipe_logreg = ImPipeline(steps=[('ct',ct),\n",
    "                            ('sm', SMOTE(random_state=3, sampling_strategy='minority')),\n",
    "                            ('logreg',LogisticRegression(random_state=3, max_iter=5000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7735150300601202, 0.789515806322529)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imb_pipe_logreg.fit(X_train, y_train)\n",
    "cross_val_score(imb_pipe_logreg, X_train, y_train).mean(), imb_pipe_logreg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "imb_pipe_knn = ImPipeline(steps=[('ct',ct),\n",
    "                            ('sm', SMOTE(random_state=3, sampling_strategy='minority')),\n",
    "                            ('knn',KNeighborsClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6398476953907816, 0.8071228491396558)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imb_pipe_knn.fit(X_train, y_train)\n",
    "cross_val_score(imb_pipe_knn, X_train, y_train).mean(), imb_pipe_knn.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "imb_pipe_dtc = ImPipeline(steps=[('ct',ct),\n",
    "                            ('sm', SMOTE(random_state=3, sampling_strategy='minority')),\n",
    "                            ('dtc',DecisionTreeClassifier(random_state=3))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9071599198396794, 1.0)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imb_pipe_dtc.fit(X_train, y_train)\n",
    "cross_val_score(imb_pipe_dtc, X_train, y_train).mean(), imb_pipe_dtc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "imb_pipe_rfc = ImPipeline(steps=[('ct',ct),\n",
    "                            ('sm', SMOTE(random_state=3, sampling_strategy='minority')),\n",
    "                            ('rfc',RandomForestClassifier(random_state=3))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.923167134268537, 1.0)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imb_pipe_rfc.fit(X_train, y_train)\n",
    "cross_val_score(imb_pipe_rfc, X_train, y_train).mean(), imb_pipe_rfc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "imb_pipe_gbc = ImPipeline(steps=[('ct',ct),\n",
    "                            ('sm', SMOTE(random_state=3, sampling_strategy='minority')),\n",
    "                            ('gbc', GradientBoostingClassifier(random_state=3))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9291679358717436, 0.9531812725090036)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imb_pipe_gbc.fit(X_train, y_train)\n",
    "cross_val_score(imb_pipe_gbc, X_train, y_train).mean(), imb_pipe_gbc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'gbc__loss': ['deviance', 'exponential'],\n",
    "          'gbc__max_depth': [2, 5, 10]}\n",
    "\n",
    "\n",
    "gs = GridSearchCV(estimator=imb_pipe_gbc,\n",
    "                 param_grid=parameters,\n",
    "                 cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ct',\n",
       "                                        ColumnTransformer(remainder='passthrough',\n",
       "                                                          transformers=[('subpipe_cat',\n",
       "                                                                         Pipeline(steps=[('ohe',\n",
       "                                                                                          OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                                        sparse=False))]),\n",
       "                                                                         [0,\n",
       "                                                                          2])])),\n",
       "                                       ('sm',\n",
       "                                        SMOTE(random_state=3,\n",
       "                                              sampling_strategy='minority')),\n",
       "                                       ('gbc',\n",
       "                                        GradientBoostingClassifier(random_state=3))]),\n",
       "             param_grid={'gbc__loss': ['deviance', 'exponential'],\n",
       "                         'gbc__max_depth': [2, 5, 10]})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gbc__loss': 'exponential', 'gbc__max_depth': 5}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9463751503006013"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "imb_pipe_gbc = ImPipeline(steps=[('ct',ct),\n",
    "                            ('sm', SMOTE(random_state=3, sampling_strategy='minority')),\n",
    "                            ('gbc', GradientBoostingClassifier(loss='exponential', max_depth=5, random_state=3))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9463751503006013, 0.9807923169267707)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imb_pipe_gbc.fit(X_train, y_train)\n",
    "cross_val_score(imb_pipe_gbc, X_train, y_train).mean(), imb_pipe_gbc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9447735470941883, 0.974389755902361)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imb_pipe_gbc = ImPipeline(steps=[('ct',ct),\n",
    "                            ('sm', SMOTE(random_state=3, sampling_strategy='minority')),\n",
    "                            ('gbc', GradientBoostingClassifier(loss='exponential', max_depth=4, random_state=3))])\n",
    "imb_pipe_gbc.fit(X_train, y_train)\n",
    "cross_val_score(imb_pipe_gbc, X_train, y_train).mean(), imb_pipe_gbc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weesn\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x26cea62e760>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(gs.best_estimator_, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Our final model's accuracy on the test set is 0.94. \n",
      "\n",
      "Our final model's recall on the test set is 0.76 \n",
      "\n",
      "Our final model's precision on the test set is 0.83 \n",
      "\n",
      "Our final model's f1-score on the test is 0.79.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat = gs.best_estimator_.predict(X_test)  #print was acquired from davids lecture\n",
    "print(f\"\"\"\n",
    "Our final model's accuracy on the test set is {round(accuracy_score(y_test, y_hat), 2)}. \\n\n",
    "Our final model's recall on the test set is {round(recall_score(y_test, y_hat), 2)} \\n\n",
    "Our final model's precision on the test set is {round(precision_score(y_test, y_hat), 2)} \\n\n",
    "Our final model's f1-score on the test is {round(f1_score(y_test, y_hat), 2)}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recall score.  .76 recall score on test data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
